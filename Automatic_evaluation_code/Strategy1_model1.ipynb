{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_df2U9b2o3Gs"
   },
   "source": [
    "# Automatic evaluation part 1\n",
    "\n",
    "This is demo code for Automatic evaluation part 1.\n",
    "\n",
    "Input files include text, image, csv table and the MC questions. The output are the chatGPT response txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aS_hJkFyUwe"
   },
   "source": [
    "## Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17961,
     "status": "ok",
     "timestamp": 1751369347539,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "ZdpMDYqiT9FT",
    "outputId": "66eceab2-83ad-4e8f-e63e-101f5c1a26e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n",
      "Collecting anthropic\n",
      "  Downloading anthropic-0.55.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
      "Downloading anthropic-0.55.0-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: anthropic\n",
      "Successfully installed anthropic-0.55.0\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "%pip install python-docx\n",
    "%pip install anthropic\n",
    "# !pip install mistralai\n",
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1751369374580,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "1TxsEQyCS3NO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "\n",
    "from openai import OpenAI\n",
    "#DAMN https://ai.google.dev/gemini-api/docs/migrate\n",
    "#import google.generativeai as genai\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "import anthropic\n",
    "# from mistralai import Mistral\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import docx\n",
    "import openpyxl\n",
    "import base64\n",
    "import chardet\n",
    "from typing import Union, List, Dict\n",
    "import tiktoken\n",
    "import time\n",
    "import httpx\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1751369558582,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "-dLRchUrwEmf",
    "outputId": "d7b0fd6c-a4d6-480b-bc8b-36f7f7c86fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.1\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "print(genai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5dDChnDjJ6n"
   },
   "source": [
    "## File Reading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HQvYJYSY4u6"
   },
   "outputs": [],
   "source": [
    "def file_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a DOCX, XLSX, CSV, JSON, RMD (R Markdown), or PY file\n",
    "    into a text string suitable for LLM input.\n",
    "\n",
    "    :param file_path: The path to the file to be converted.\n",
    "    :return: A single string containing the file’s textual contents.\n",
    "    \"\"\"\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    ext = ext.lower()\n",
    "\n",
    "    if ext == \".docx\":\n",
    "        return _docx_to_text(file_path)\n",
    "    elif ext == \".xlsx\":\n",
    "        return _xlsx_to_text(file_path)\n",
    "    elif ext == \".csv\":\n",
    "        return _csv_to_text(file_path)\n",
    "    elif ext == \".json\":\n",
    "        return _json_to_text(file_path)\n",
    "    elif ext == \".rmd\":\n",
    "        return _rmarkdown_to_text(file_path)\n",
    "    elif ext == \".md\":\n",
    "        return _rmarkdown_to_text(file_path)\n",
    "    elif ext == \".py\":\n",
    "        return _python_to_text(file_path)\n",
    "    elif ext == \".txt\":\n",
    "        return _txt_to_text(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "\n",
    "\n",
    "def _docx_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a DOCX file and extracts all text paragraphs.\n",
    "    Requires 'python-docx' (pip install python-docx).\n",
    "    \"\"\"\n",
    "    if docx is None:\n",
    "        raise ImportError(\"Missing dependency 'python-docx'. Install via `pip install python-docx`.\")\n",
    "\n",
    "    doc = docx.Document(file_path)\n",
    "    paragraphs = [para.text for para in doc.paragraphs]\n",
    "    return \"\\n\".join(paragraphs)\n",
    "\n",
    "\n",
    "def _xlsx_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads an XLSX file and concatenates all cells as text.\n",
    "    Requires 'openpyxl' (pip install openpyxl).\n",
    "    \"\"\"\n",
    "    if openpyxl is None:\n",
    "        raise ImportError(\"Missing dependency 'openpyxl'. Install via `pip install openpyxl`.\")\n",
    "\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    all_text = []\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        sheet = wb[sheet_name]\n",
    "        all_text.append(f\"--- Sheet: {sheet_name} ---\")\n",
    "        for row in sheet.iter_rows(values_only=True):\n",
    "            row_text = [str(cell) if cell is not None else \"\" for cell in row]\n",
    "            all_text.append(\"\\t\".join(row_text))\n",
    "\n",
    "    return \"\\n\".join(all_text)\n",
    "\n",
    "\n",
    "def _csv_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a CSV file line by line and returns its text representation.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            rows.append(\"\\t\".join(row))\n",
    "    return \"\\n\".join(rows)\n",
    "\n",
    "\n",
    "def _json_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a JSON file and returns its pretty-printed JSON string.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return json.dumps(data, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def _rmarkdown_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    R Markdown files are basically text files with embedded code.\n",
    "    We’ll just read the raw text for simplicity.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def _txt_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a text file and returns its content as a string.\n",
    "    Automatically detects encoding to avoid decoding errors.\n",
    "    \"\"\"\n",
    "    #import chardet\n",
    "    try:\n",
    "        # Detect the file encoding\n",
    "        with open(file_path, 'rb') as file:\n",
    "            raw_data = file.read()\n",
    "            detected = chardet.detect(raw_data)\n",
    "            encoding = detected['encoding']\n",
    "\n",
    "        # Read the file with the detected encoding\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "def _python_to_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Python (.py) files are plain text. Just read the entire file content.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        code = f.read()\n",
    "    return code\n",
    "\n",
    "def encode_image(image_path: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Encode an image file to base64 and return its MIME type.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "\n",
    "    # Read and encode image\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Get MIME type based on file extension\n",
    "    _, extension = os.path.splitext(image_path)\n",
    "    extension = extension.lower()\n",
    "\n",
    "    mime_type = {\n",
    "        '.jpg': 'image/jpeg',\n",
    "        '.jpeg': 'image/jpeg',\n",
    "        '.png': 'image/png',\n",
    "        '.gif': 'image/gif',\n",
    "        '.webp': 'image/webp'\n",
    "    }.get(extension)\n",
    "\n",
    "    if not mime_type:\n",
    "        raise ValueError(f\"Unsupported image format: {extension}\")\n",
    "\n",
    "    return base64_data, mime_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjWA0AWljFv8"
   },
   "source": [
    "## Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kumqmgLjFgQ"
   },
   "outputs": [],
   "source": [
    "def generate_MC_answer_openai(api_key: str, dir: str, rfile_path: str, images_folder_path: str, dfile_path: str, system_prompt: str = None, model: str = \"gpt-4o\") -> str:\n",
    "    \"\"\"\n",
    "    Generates a result paragraph based on the given report and multiple-choice document using OpenAI's API.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        report_txt (str): The main report content to analyze.\n",
    "        mc_doc (str): The multiple-choice document content for the question.\n",
    "        system_prompt (str, optional): The system-level instruction for the AI. Defaults to a biological writing prompt.\n",
    "        model (str, optional): The OpenAI model to use. Defaults to \"gpt-4o\".\n",
    "\n",
    "    Returns:\n",
    "        str: The generated result paragraph.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Use a default system prompt if none is provided\n",
    "    if system_prompt is None:\n",
    "        system_prompt = (\n",
    "            \"I am a bioinformatician that has conducted some analyses but lacks the biological knowledge to interpret the results and build a cohesive narrative.\"\n",
    "            \"However, you are an expert scientist who has a strong background in both bioinformatics and biology.\"\n",
    "            \"I would like to ask you to interpret and translate my bioinformatics analyses into a coherent 'Results' section suitable for a high-impact interdisciplinary scientific journal.\"\n",
    "\t\t\t\t\t  \"I have provided you with a .txt file containing the outputs from my analysis, and in some cases, additional supporting materials such as plots.\"\n",
    "            \"These files are the core analytics you will need to synthesize and summarize into a coherent narrative. The .txt file also includes an 'LLM' detailing any specific requirements or instructions for your summary. Please read it carefully.\"\n",
    "            \"Please remember the following when completing this request: Interpret and synthesize the provided bioinformatics results into a clear and logical narrative, complete any specific requests outlined in the LLM task, include quantitative evidence from the analyses to support your conclusions, and include relevant literature to support or contextualise your findings in your summary.\"\n",
    "        )\n",
    "\n",
    "    # Prepare the input message\n",
    "    user_prompt=[]\n",
    "\n",
    "    user_prompt.append(\n",
    "       \"I have provided you with a .txt file containing the outputs from my analysis, and in some cases, additional supporting materials such as plots. Please synthesize and summarize the contents of the file(s) into a coherent narrative. Be sure to read the 'LLM task' in the .txt file.\\n\"\n",
    "        )\n",
    "\n",
    "    if pd.notna(rfile_path):\n",
    "        report_txt = file_to_text(os.path.join(dir,rfile_path))\n",
    "        user_prompt.append(\"Txt file:\\n\" + report_txt)\n",
    "\n",
    "    # if pd.notna(dfile_path):\n",
    "    #     data_txt = file_to_text(os.path.join(dir,dfile_path))\n",
    "    #     user_prompt.append(\"I have a csv file:\" + \"\\n\" + data_txt)\n",
    "\n",
    "    if pd.notna(dfile_path):\n",
    "        # Split dfile_path into individual file paths\n",
    "        file_paths = dfile_path.split(\"\\n\")\n",
    "        if len(file_paths)>1:\n",
    "            user_prompt.append(\"CSV files:\\n\")\n",
    "        else:\n",
    "            user_prompt.append(\"CSV file:\\n\")\n",
    "        for file_path in file_paths:\n",
    "            # Process each file path\n",
    "            full_path = os.path.join(dir, file_path.strip())  # Strip any extra spaces or newline characters\n",
    "            if os.path.exists(full_path):  # Ensure the file exists before reading\n",
    "                data_txt = file_to_text(full_path)  # Convert the file to text\n",
    "                user_prompt.append(data_txt+\"\\n\")\n",
    "            else:\n",
    "                print(f\"File not found: {full_path}\")\n",
    "\n",
    "\n",
    "    if pd.notna(images_folder_path):\n",
    "        image_path_list = []\n",
    "        image_dir=os.path.join(dir,images_folder_path,\"figure-markdown_strict\")\n",
    "        for file_name in os.listdir(image_dir):\n",
    "            if file_name.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\")):\n",
    "                image_path_list.append(os.path.join(image_dir, file_name))\n",
    "        image_file_list = [encode_image(item) for item in image_path_list]\n",
    "        for image_file,mime_type in image_file_list:\n",
    "            user_prompt.append(\"Image file:\\n\")\n",
    "            user_prompt.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:{mime_type};base64,{image_file}\",\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "    ]\n",
    "\n",
    "    print(\"Number of tokens(Lijia):\", count_tokens(messages,model=model))\n",
    "    print(\"Number of tokens(Xumou):\", num_tokens_from_messages(messages,model=model))\n",
    "\n",
    "\n",
    "    #Generate the completion\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=model,\n",
    "            # temperature=0.1\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        # raise RuntimeError(f\"Error generating result paragraph: {e}\")\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "            # Return a default error string\n",
    "        return \"error\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3O0IeMgiONu"
   },
   "outputs": [],
   "source": [
    "def generate_MC_answer_google_gemini(api_key: str, dir: str, rfile_path: str, images_folder_path: str, dfile_path: str, system_prompt: str = None, model: str = \"gemini-2.0-flash-exp\") -> str:\n",
    "    \"\"\"\n",
    "    Generates a result paragraph based on the given report and multiple-choice document using Google's Generative AI API.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): Your Google Generative AI API key.\n",
    "        report_txt (str): The main report content to analyze.\n",
    "        mc_doc (str): The multiple-choice document content for the question.\n",
    "        system_prompt (str, optional): The system-level instruction for the AI. Defaults to a biological writing prompt.\n",
    "        model (str, optional): The Google Generative AI model to use. Defaults to \"models/chat-bison-001\".\n",
    "\n",
    "    Returns:\n",
    "        str: The generated result paragraph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configure the API key\n",
    "    client = genai.Client(api_key=api_key)\n",
    "\n",
    "    # Use a default system prompt if none is provided\n",
    "    if system_prompt is None:\n",
    "        system_prompt = (\n",
    "            \"I am a bioinformatician that has conducted some analyses but lacks the biological knowledge to interpret the results and build a cohesive narrative.\"\n",
    "            \"However, you are an expert scientist who has a strong background in both bioinformatics and biology.\"\n",
    "            \"I would like to ask you to interpret and translate my bioinformatics analyses into a coherent 'Results' section suitable for a high-impact interdisciplinary scientific journal.\"\n",
    "\t\t\t\t\t  \"I have provided you with a .txt file containing the outputs from my analysis, and in some cases, additional supporting materials such as plots.\"\n",
    "            \"These files are the core analytics you will need to synthesize and summarize into a coherent narrative. The .txt file also includes an 'LLM' detailing any specific requirements or instructions for your summary. Please read it carefully.\"\n",
    "            \"Please remember the following when completing this request: Interpret and synthesize the provided bioinformatics results into a clear and logical narrative, complete any specific requests outlined in the LLM task, include quantitative evidence from the analyses to support your conclusions, and include relevant literature to support or contextualise your findings in your summary.\"\n",
    "        )\n",
    "\n",
    "    # Prepare the input message\n",
    "    user_prompt=[]\n",
    "    user_prompt.append(\"I have provided you with a .txt file containing the outputs from my analysis, and in some cases, additional supporting materials such as plots. Please synthesize and summarize the contents of the file(s) into a coherent narrative. Be sure to read the 'LLM task' in the .txt file. \\n\")\n",
    "\n",
    "\n",
    "    if pd.notna(rfile_path):\n",
    "        report_txt = file_to_text(os.path.join(dir,rfile_path))\n",
    "        user_prompt.append(\"Txt file:\\n\" + report_txt)\n",
    "\n",
    "    # if pd.notna(dfile_path):\n",
    "    #     data_txt = file_to_text(os.path.join(dir,dfile_path))\n",
    "    #     user_prompt.append(\"I have a csv file:\" + \"\\n\" + data_txt)\n",
    "\n",
    "    if pd.notna(dfile_path):\n",
    "        # Split dfile_path into individual file paths\n",
    "        file_paths = dfile_path.split(\"\\n\")\n",
    "        if len(file_paths)>1:\n",
    "            user_prompt.append(\"CSV files:\\n\")\n",
    "        else:\n",
    "            user_prompt.append(\"CSV file:\\n\")\n",
    "        for file_path in file_paths:\n",
    "            # Process each file path\n",
    "            full_path = os.path.join(dir, file_path.strip())  # Strip any extra spaces or newline characters\n",
    "            if os.path.exists(full_path):  # Ensure the file exists before reading\n",
    "                data_txt = file_to_text(full_path)  # Convert the file to text\n",
    "                user_prompt.append(data_txt+\"\\n\")\n",
    "            else:\n",
    "                print(f\"File not found: {full_path}\")\n",
    "\n",
    "\n",
    "    if pd.notna(images_folder_path):\n",
    "        image_path_list = []\n",
    "        image_dir=os.path.join(dir,images_folder_path,\"figure-markdown_strict\")\n",
    "        for file_name in os.listdir(image_dir):\n",
    "            if file_name.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\")):\n",
    "                image_path_list.append(os.path.join(image_dir, file_name))\n",
    "        image_file_list = [encode_image(item) for item in image_path_list]\n",
    "        for image_file,mime_type in image_file_list:\n",
    "            user_prompt.append(\"Image file:\\n\")\n",
    "            user_prompt.append(\n",
    "                # {'mime_type': mime_type, 'data': image_file}\n",
    "                # image_file\n",
    "                types.Part.from_bytes(data=image_file, mime_type=mime_type)\n",
    "            )\n",
    "\n",
    "    # user_prompt.append(\"Please summarise all the information above and answer the following question:\" + \"\\n\"\n",
    "    #                    + mc_txt +\n",
    "    #                    \"\\nPlease provide only the letter of the correct option (A, B, C, D, or E). \\\n",
    "    #                    Do not include the answer text, explanations, or any other information.\")\n",
    "\n",
    "    # messages = [\n",
    "    #     {\"role\": \"user\", \"parts\": f\"{user_prompt}\"},\n",
    "    # ]\n",
    "    # print(user_prompt)\n",
    "\n",
    "        # Create the model\n",
    "    # generation_config = {\n",
    "    #   # \"temperature\": 0.1,\n",
    "    #   \"top_p\": 0.95,\n",
    "    #   \"top_k\": 40,\n",
    "    #   \"max_output_tokens\": 8192,\n",
    "    #   \"response_mime_type\": \"text/plain\",\n",
    "    # }\n",
    "\n",
    "    try:\n",
    "        # chat_session = model.start_chat()\n",
    "        # chat_session = model.start_chat(history=messages)\n",
    "        # Send an additional message if needed (optional)\n",
    "        # response = chat_session.send_message(messages)\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=user_prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                # generation_config=generation_config,\n",
    "                # temperature= 0.5,\n",
    "                response_mime_type=\"text/plain\",\n",
    "                system_instruction=system_prompt,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        # raise RuntimeError(f\"Error generating result paragraph with Generative AI: {e}\")\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "            # Return a default error string\n",
    "        return \"error\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wG3Z0Il-vRU"
   },
   "outputs": [],
   "source": [
    "def generate_MC_answer_claude(api_key: str, dir: str, rfile_path: str, images_folder_path: str, dfile_path: str,  system_prompt: str = None, model: str = \"claude-3-5-sonnet-20241022\") -> str:\n",
    "    \"\"\"\n",
    "    Generates a multiple-choice answer based on the given report and document using Claude's API.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): Your Claude API key.\n",
    "        report_txt (str): The main report content to analyze.\n",
    "        mc_doc (str): The multiple-choice document content for the question.\n",
    "        system_prompt (str, optional): The system-level instruction for the AI. Defaults to a biological writing prompt.\n",
    "        model (str, optional): The Claude model to use. Defaults to \"claude-3-5-sonnet-20241022\".\n",
    "\n",
    "    Returns:\n",
    "        str: The multiple-choice answer generated by Claude.\n",
    "    \"\"\"\n",
    "    # Initialize the Claude API client\n",
    "    client = anthropic.Anthropic(\n",
    "        api_key=api_key\n",
    "    )\n",
    "\n",
    "    # Use a default system prompt if none is provided\n",
    "    if system_prompt is None:\n",
    "        system_prompt = (\n",
    "            \"I am a bioinformatician that has conducted some analyses but lacks the biological knowledge to interpret the results and build a cohesive narrative.\"\n",
    "            \"However, you are an expert scientist who has a strong background in both bioinformatics and biology.\"\n",
    "            \"I would like to ask you to interpret and translate my bioinformatics analyses into a coherent 'Results' section suitable for a high-impact interdisciplinary scientific journal.\"\n",
    "\t\t\t\t\t  \"I have provided you with a .txt file containing the outputs from my analysis, and in some cases, additional supporting materials such as plots.\"\n",
    "            \"These files are the core analytics you will need to synthesize and summarize into a coherent narrative. The .txt file also includes an 'LLM' detailing any specific requirements or instructions for your summary. Please read it carefully.\"\n",
    "            \"Please remember the following when completing this request: Interpret and synthesize the provided bioinformatics results into a clear and logical narrative, complete any specific requests outlined in the LLM task, include quantitative evidence from the analyses to support your conclusions, and include relevant literature to support or contextualise your findings in your summary.\"\n",
    "        )\n",
    "\n",
    "    # Prepare the input message\n",
    "    user_prompt=[]\n",
    "\n",
    "    user_prompt.append({\"type\": \"text\", \"text\":\"I have provided you with a .txt file containing the outputs from my analysis, and in some cases, additional supporting materials such as plots. Please synthesize and summarize the contents of the file(s) into a coherent narrative. Be sure to read the 'LLM task' in the .txt file.\\n\"})\n",
    "\n",
    "\n",
    "    if pd.notna(rfile_path):\n",
    "        report_txt = file_to_text(os.path.join(dir,rfile_path))\n",
    "        user_prompt.append({\"type\": \"text\", \"text\":\"Txt file:\\n\" + report_txt})\n",
    "\n",
    "    # if pd.notna(dfile_path):\n",
    "    #     data_txt = file_to_text(os.path.join(dir,dfile_path))\n",
    "    #     user_prompt.append(\"I have a csv file:\" + \"\\n\" + data_txt)\n",
    "\n",
    "    if pd.notna(dfile_path):\n",
    "        # Split dfile_path into individual file paths\n",
    "        file_paths = dfile_path.split(\"\\n\")\n",
    "        if len(file_paths)>1:\n",
    "            user_prompt.append({\"type\": \"text\", \"text\":\"CSV files:\\n\"})\n",
    "        else:\n",
    "            user_prompt.append({\"type\": \"text\", \"text\":\"CSV file:\\n\"})\n",
    "        for file_path in file_paths:\n",
    "            # Process each file path\n",
    "            full_path = os.path.join(dir, file_path.strip())  # Strip any extra spaces or newline characters\n",
    "            if os.path.exists(full_path):  # Ensure the file exists before reading\n",
    "                data_txt = file_to_text(full_path)  # Convert the file to text\n",
    "                user_prompt.append({\"type\": \"text\", \"text\": data_txt+\"\\n\"})\n",
    "            else:\n",
    "                print(f\"File not found: {full_path}\")\n",
    "\n",
    "\n",
    "    if pd.notna(images_folder_path):\n",
    "        image_path_list = []\n",
    "        image_dir=os.path.join(dir,images_folder_path,\"figure-markdown_strict\")\n",
    "        for file_name in os.listdir(image_dir):\n",
    "            if file_name.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\")):\n",
    "                image_path_list.append(os.path.join(image_dir, file_name))\n",
    "        image_file_list = [encode_image(item) for item in image_path_list]\n",
    "        for image_file,mime_type in image_file_list:\n",
    "            user_prompt.append( \"Image file:\\n\")\n",
    "            user_prompt.append(\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": mime_type,  # e.g., \"image/jpeg\"\n",
    "                    \"data\": image_file\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "    ]\n",
    "\n",
    "    # print(messages)\n",
    "\n",
    "    # Call the Claude API to generate the response\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=8192,\n",
    "           # temperature=0.1,\n",
    "            system=system_prompt,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.content[0].text # Extract the generated content\n",
    "    except Exception as e:\n",
    "        # raise RuntimeError(f\"Error generating multiple-choice answer with Claude: {e}\")\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "            # Return a default error string\n",
    "        return \"error\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HxN-IxvyZkb"
   },
   "source": [
    "## Mount google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20396,
     "status": "ok",
     "timestamp": 1744598785179,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "XGWHA_iY7MTa",
    "outputId": "64fd49e0-ba36-46af-ba08-a01151cd857e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG_egwC9yeS9"
   },
   "source": [
    "## Read Prompt Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1744598788443,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "TgG4tJV99Ecr",
    "outputId": "807ab234-5026-470c-d287-34d14f6d56b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Authors          Google Folder              CaseStudy_ID  \\\n",
      "0  EXAMPLE 1  Bioinformatics_method  Dataset_method_increment   \n",
      "1  EXAMPLE 2  Bioinformatics_method  Dataset_method_increment   \n",
      "2  EXAMPLE 3  Bioinformatics_method  Dataset_method_increment   \n",
      "3         DK                Pathway          Kidney_pathway_1   \n",
      "4         DK                     DE               Kidney_DE_1   \n",
      "5         DK                Pathway          Kidney_pathway_2   \n",
      "\n",
      "                   Sample_ID LLM task updated?    Input type  \\\n",
      "0  Dataset_method_incrementA                No         Graph   \n",
      "1   Dataset_method_increment                No          Data   \n",
      "2  Dataset_method_incrementB                No   Code + Data   \n",
      "3          Kidney_pathway_1B                No  Code + Graph   \n",
      "4                Kidney_DE_1                No   Code + Data   \n",
      "5           Kidney_pathway_2                No   Code + Data   \n",
      "\n",
      "       RMD_Code_input_ID           TXT_input_ID   Graphics_input_Folder  \\\n",
      "0                    NaN                    NaN                     NaN   \n",
      "1                    NaN                    NaN                     NaN   \n",
      "2                    NaN                    NaN                     NaN   \n",
      "3  Kidney_pathway_1B.Rmd  Kidney_pathway_1B.txt  Kidney_pathway_1_files   \n",
      "4        Kidney_DE_1.Rmd        Kidney_DE_1.txt                     NaN   \n",
      "5   Kidney_pathway_2.Rmd   Kidney_pathway_2.txt                     NaN   \n",
      "\n",
      "  Data_input_ID  ... Task Difficulty Task Difficulty (evaluated by Fei)  \\\n",
      "0           NaN  ...          Simple                             Simple   \n",
      "1           NaN  ...             NaN                             Simple   \n",
      "2           NaN  ...             NaN                             Simple   \n",
      "3           NaN  ...          Simple                            Median    \n",
      "4           NaN  ...          Simple                             Simple   \n",
      "5           NaN  ...          Simple                            Median    \n",
      "\n",
      "  (# clues given - score by human)   \\\n",
      "0                                 0   \n",
      "1                                 1   \n",
      "2                                 2   \n",
      "3                                 2   \n",
      "4                                 2   \n",
      "5                                 2   \n",
      "\n",
      "  Task (this should match what's in your .rmd file)  MC1 ID (easy)  \\\n",
      "0  What are the pathways that are most associated...           1.0   \n",
      "1  These differentially expressed genes were iden...           4.0   \n",
      "2  These differentially expressed genes were iden...           7.0   \n",
      "3  This is a Gene Set Enrichment Analysis (GSEA) ...           1.0   \n",
      "4  This is a differential expression analysis of ...           1.0   \n",
      "5  This is a Gene Set Enrichment Analysis (GSEA) ...           2.0   \n",
      "\n",
      "   MC2 ID (harder) MC3 ID (harder)  \\\n",
      "0                2               3   \n",
      "1                5               6   \n",
      "2                8               9   \n",
      "3                -               -   \n",
      "4                -               -   \n",
      "5              NaN             NaN   \n",
      "\n",
      "   Analytical focus (Notes, bioinformatics category) Personal note Lijia_note  \n",
      "0  classic pathway analysis, I've filtered for si...           NaN        NaN  \n",
      "1  classic pathway analysis, I've filtered for si...           NaN        NaN  \n",
      "2  classic pathway analysis, I've filtered for si...           NaN        NaN  \n",
      "3                                            Pathway           NaN        NaN  \n",
      "4                                                 DE           NaN        NaN  \n",
      "5                                            Pathway           NaN        NaN  \n",
      "\n",
      "[6 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "## Don't change this url\n",
    "url = 'https://docs.google.com/spreadsheets/d/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/export?format=csv&gid=XXXXXXXXXXXXXXX'\n",
    "case_df = pd.read_csv(url)\n",
    "print(case_df.head(6))\n",
    "df=case_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkJ_Gpy_kC7g"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRzms8_2SE83"
   },
   "outputs": [],
   "source": [
    "OPENAI_api_key= \"sk-\"\n",
    "GEMINI_api_key= \"AI\"\n",
    "CLAUDE_api_key=\"sk-\"\n",
    "## root_dir is the only path that you need to modify by yourself.\n",
    "## You may find the shared Proj-LLM-Bioinfo-Interpretation2024 folder in the /content/drive/MyDrive,\n",
    "## so the dir path can be /content/drive/MyDrive/Proj-LLM-Bioinfo-Interpretation2024/Rmd_word_document/\n",
    "root_dir = \"/content/drive/MyDrive/Usyd/Proj-LLM-Bioinfo-Interpretation2024/Rmd_word_document/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1744598794583,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "JNYefRRXUmXq",
    "outputId": "33cb7bc6-6205-4e7b-df7b-2f4bc7e19c14"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/Usyd/Proj-LLM-Bioinfo-Interpretation2024/Rmd_word_document/CCI/Covid_CCI_8/CCI_chua_ligand_receptor_contribution_CXCL_only_plot.txt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### test\n",
    "os.path.join(root_dir, df['Google Folder'][55], df['CaseStudy_ID'][55],df['TXT_input_ID'][55])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAI8aXYmlrpA"
   },
   "source": [
    "### Multiple Choice questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1744598908653,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "LKd7nmdOMqoj",
    "outputId": "20e440a9-bd09-4608-ea28-2c223118d2c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   4,   5,  10,  57,  58,  59,  79,  80, 100, 101, 102, 103,\n",
       "       112, 113, 114, 115, 116, 117, 118, 119])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_check = ['TXT_input_ID', 'Graphics_input_Folder', 'Data_input_ID']\n",
    "index=np.where(case_df[\"Authors\"] == \"DK\")[0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1148073,
     "status": "ok",
     "timestamp": 1744623370236,
     "user": {
      "displayName": "Lijia Yu",
      "userId": "00870759781493577221"
     },
     "user_tz": -600
    },
    "id": "59JIHhkrSGsE",
    "outputId": "5c7f4277-2d94-4109-ce6c-b94400576a8b"
   },
   "outputs": [],
   "source": [
    "columns_to_check = ['TXT_input_ID', 'Graphics_input_Folder', 'Data_input_ID']\n",
    "index=np.where(case_df[\"Authors\"] == \"JG\")[0]\n",
    "for idx in index: #range(len(mc_df)):range(18,19), range(len(case_df))[5:]\n",
    "    if pd.notna(case_df['Google Folder'][idx]) and pd.notna(case_df['Sample_ID'][idx]):\n",
    "        subfolder = os.path.join(root_dir, case_df['Google Folder'][idx], case_df['CaseStudy_ID'][idx])\n",
    "        row_entry=case_df[case_df['Sample_ID'] == case_df['Sample_ID'][idx]].iloc[0]\n",
    "        # print(row_entry)\n",
    "        print(idx)\n",
    "        print(row_entry[\"Sample_ID\"])\n",
    "        gpt4o_answer=generate_MC_answer_openai(api_key=OPENAI_api_key, dir=subfolder,\n",
    "                                  rfile_path=row_entry[\"TXT_input_ID\"], images_folder_path=row_entry[\"Graphics_input_Folder\"],\n",
    "                                  dfile_path=row_entry[\"Data_input_ID\"],  model = \"gpt-4o\")\n",
    "        gemini_answer=generate_MC_answer_google_gemini(api_key=GEMINI_api_key, dir=subfolder,\n",
    "                                  rfile_path=row_entry[\"TXT_input_ID\"], images_folder_path=row_entry[\"Graphics_input_Folder\"],\n",
    "                                  dfile_path=row_entry[\"Data_input_ID\"],  model = \"gemini-2.0-flash\")\n",
    "        claude_answer=generate_MC_answer_claude(api_key=CLAUDE_api_key, dir=subfolder,\n",
    "                                  rfile_path=row_entry[\"TXT_input_ID\"], images_folder_path=row_entry[\"Graphics_input_Folder\"],\n",
    "                                  dfile_path=row_entry[\"Data_input_ID\"],  model = \"claude-3-7-sonnet-20250219\")\n",
    "\n",
    "        time.sleep(60)\n",
    "        model_answers = {\n",
    "                        \"gpt-4o\": gpt4o_answer,\n",
    "                        \"gemini-2.0-flash\": gemini_answer,\n",
    "                        \"claude-3-7-sonnet-20250219\": claude_answer\n",
    "                    }\n",
    "        for j in model_answers.keys():\n",
    "            file_path=\"/content/drive/MyDrive/Usyd/Proj-LLM-Bioinfo-Interpretation2024/Report_output/\"+row_entry['Sample_ID']+\".\"+j+\".txt\"\n",
    "            # print(file_path)\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(model_answers[j])\n",
    "            print(f\"File saved to: {file_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
